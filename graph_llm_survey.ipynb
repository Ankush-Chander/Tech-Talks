{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbcbbaf-a7df-4743-9f78-638954261f7a",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## [Large Language Models on Graphs: A Comprehensive Survey](https://arxiv.org/pdf/2312.02783.pdf)\n",
    "Authors: Bowen Jin*, Gang Liu*, Chi Han*, Meng Jiang, Heng Ji, Jiawei Han\n",
    "\n",
    "\n",
    "Presented by:  \n",
    "Ankush Chander  \n",
    "KDM Lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3af2d-a2ce-4d45-8b36-fff084ad7013",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<img src=\"img/graph_llm_survey/graph_llm_roles_relationship.png\" width=\"550\" height=\"550\">\n",
    "<hr>\n",
    "Image credit: from paper "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef7e43-7e8d-415c-aac4-707a6b516ae8",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Pure Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c29b5e-2754-4fcb-bd08-61c36b67ebcd",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### LLM as  predictor  \n",
    "**Tasks:**\n",
    "1. Direct Answering: eg-  \n",
    "   How to give graph as input?    \n",
    "   a. Plainly Verbalizing Graphs    \n",
    "   b. Paraphrasing graphs  \n",
    "   c. Encoding Graphs Into Implicit Feature Sequences   \n",
    "3. Heurestic reasoning  \n",
    "   a. Step by step (inspired by Chain-of-thought)  \n",
    "   b. Retrieving subgraph as evidence  \n",
    "   c. Searching on graphs: \"At each step, the LLMs retrieve neighbors of the current nodes and then decide to answer the question or continue the next search step.\"\n",
    "5. Algorithmic reasoning: Ask LLM to fetch the algoritms and then use them step by step to answer the question. \n",
    "<hr>\n",
    "General findings: *\"Improved performance on simpler problems, such as cycle detection and shortest path detection. Inconsistent performance on complex problems, such as Hamiltonian path finding and topological sorting.\"*    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71820943-e0d1-420e-8ef2-4418e7b1da93",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Text atrributed Graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec60b17-77f0-42c3-9463-4e78aebf800b",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Text atrributed Graphs(1)\n",
    "\n",
    "### LLM as predictor\n",
    "<img src=\"img/graph_llm_survey/llm_predictor_text_attributed_graphs.png\">\n",
    "\n",
    "1. Graph as a sequence (input)  \n",
    "    a. Rule-based: Linearizing Graphs into Text Sequence with Rules  \n",
    "    b. GNN-based: Encoding Graphs into Special Tokens with GNNs  \n",
    "       i) use GNN to generate graph tokens and project them to token space using learnable matrices  \n",
    "       ii) use graph info as positional encoding and add them to text sequence  \n",
    "2. Graph empowered LLMs (via architecture change)  \n",
    "   a. Modify architecture to have a graph encoding component and a text concoding component\n",
    "3. Graph aware LLMS (via finetuning)  \n",
    "   a. Take vanilla model as base model and finetune on graph structure signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e425ca6-436d-4171-8918-c4681ce9549d",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Text atrributed Graphs(2)\n",
    "### LLM as encoder\n",
    "1. **Single step:** Train LLM and GNN together \n",
    "2. **Two step:** First  LLM to graph centric tasks, then train LLM+GNN together  \n",
    "3. **Data augmentation:** Use another LLM to add extra information about nodes and then train LLM+GN   \n",
    "4. **Distillation:** serve the LLM-GNN cascade pipeline as the teacher model\n",
    "and distill it into an LLM as the student model.  \n",
    "<img src=\"img/graph_llm_survey/llm_as_encoder.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e13c8c-bd5d-403a-b575-ed6c59646096",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Discussion**:  \n",
    "1. Current “LLMs as encoders” methods or LLM-GNN cascaded architectures are mainly focusing on representation learning, given the single embedding propagation-aggregation mechanism of GNNs, which prevents it from being adopted to generation tasks (e.g., node/text generation).  \n",
    "2. Distillation suffer from efficiency issues since the model needs to conduct neighbor sampling and then embedding encoding for each neighboring node.\n",
    "Although there are methods that explore distilling the learned LLM-GNN model into an LLM model for fast inference, they are far from enough given that the inference of LLM itself is time-consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5586b1c-d424-4bff-9cc9-13540270f0ef",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Text atrributed Graphs(3)\n",
    "### LLM as aligner\n",
    "1. **LLM-GNN Prediction Alignment:** This refers to training the LLM with the text data on a\n",
    "graph and training the GNN with the structure data on a graph iteratively. LLM will generate labels for nodes from the text perspective and serve them as pseudo-labels for GNN\n",
    "training, while GNN will generate labels for nodes from the structure perspective and serve them as pseudo-labels for LLM training.\n",
    "2. **LLM-GNN Latent Space Alignment:**  It denotes connecting text encoding (LLM) and structure encoding (GNN) with cross-modality contrastive learning. A similar philosophy is widely used in vision-language joint modality learning.\n",
    "<img src=\"img/graph_llm_survey/llm_aligner.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdce0da-8c0a-4cb6-aae8-d9ae42e4a44e",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Discussion:**  \n",
    "In “LLMs as Aligners” methods, most research is adopting shallow GNNs (e.g., GCN, GAT, with thousands of parameters) to be the graph encoders that are aligned\n",
    "with LLMs through iterative training (i.e., prediction alignment) or contrastive training (i.e., latent space alignment). **Although LLMs (with millions or billions of parameters)\n",
    "have strong expressive capability, the shallow GNNs (with limited representative capability) can constrain the mutual learning effectiveness between LLMs and GNNs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0dfb8f-3db0-44eb-a2f0-9bdb24d239f4",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Text paired graphs (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495f87c-576b-4ba8-acc4-219f725e189e",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### LLM as predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dfdd84-cc7a-4ea5-afac-8ae288634556",
   "metadata": {
    "editable": true,
    "slide_type": "slide",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### LLM as aligner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
