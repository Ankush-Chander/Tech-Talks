{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency in Python\n",
    "\n",
    "## at PyDelhi Virtual Meetup¶\n",
    "\n",
    "### by Ankush Chander (building at https://raxter.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    " Understand features/limitations of python so that it enables us to write efficient programs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU bound vs I/O bound\n",
    "\n",
    "\n",
    "A program is CPU bound if it would go faster if the CPU were faster, i.e. it spends the majority of its time simply using the CPU (doing calculations). A program that computes new digits of π will typically be CPU-bound, it's just crunching numbers.\n",
    "\n",
    "Eg:\n",
    "1. matrix multiplication\n",
    "2. Training NN models\n",
    "\n",
    "\n",
    "A program is I/O bound if it would go faster if the I/O subsystem was faster. Which exact I/O system is meant can vary; I typically associate it with disk, but of course networking or communication in general is common too. A program that looks through a huge file for some data might become I/O bound, since the bottleneck is then the reading of the data from disk (actually, this example is perhaps kind of old-fashioned these days with hundreds of MB/s coming in from SSDs).\n",
    "\n",
    "Eg:\n",
    "1. Database access\n",
    "2. Disk read/write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance improvement of programs\n",
    "### 1. Delegation/Outsourcing\n",
    "    \n",
    "    a. Process pool\n",
    "    \n",
    "    b. Thread pool\n",
    "\n",
    "\n",
    "### 2. Improve efficiency of the program itself\n",
    "\n",
    "    a. asynchronous programming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "A process is the instance of a computer program that is being executed by one or many threads. It contains the program code and its activity.\n",
    "It is identified by process_id.\n",
    "\n",
    "    python: os.getpid()\n",
    "    bash: ps -ef \n",
    "    \n",
    "### Thread (lightweight process)\n",
    "A thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler, which is typically a part of the operating system.\n",
    "It is identified by thread_id\n",
    "\n",
    "    python: threading.get_native_id()\n",
    "    bash: ps -T -p process_id\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coexistence of threads and processes\n",
    "![title](img/concurrency/process_thread.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded yemen flag in process:26510, thread:139876206409536\n",
      "downloaded zambia flag in process:26510, thread:139876206409536\n",
      "downloaded vietnam flag in process:26510, thread:139876206409536\n",
      "downloaded venezuela flag in process:26510, thread:139876206409536\n",
      "downloaded ukraine flag in process:26510, thread:139876206409536\n",
      "sequential io took: 16.294264714000747 seconds\n"
     ]
    }
   ],
   "source": [
    "# By default python is single threaded, blocking in nature. It means all the tasks of the program are \n",
    "#lined up on a single thread.\n",
    "\n",
    "# Example of an I/O intensive job\n",
    "\n",
    "# End goal of program:  Our program takes as input some country codes and download it\"s flags.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from concurrent import futures\n",
    "import threading\n",
    "import collections\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "BASE_URL = \"https://cdn.countryflags.com/download\"\n",
    "\n",
    "def get_flag(cc):\n",
    "    url = f\"{BASE_URL}/{cc}/flag-jpg-small.jpg\"\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:  #1. catch if result not OK\n",
    "        resp.raise_for_status()\n",
    "    else:\n",
    "        #1. log the process id and thread in which the function is being executed.\n",
    "        print(f\"downloaded {cc} flag in process:{os.getpid()}, thread:{threading.get_ident()}\")\n",
    "    return resp.content\n",
    "\n",
    "def sequential_io_function(country_codes):\n",
    "    s_time = time.perf_counter()\n",
    "    #2. download flags sequentially in a for loop     \n",
    "    for cc in country_codes: \n",
    "        get_flag(cc)\n",
    "    print(f\"sequential io took: {time.perf_counter() - s_time} seconds\")\n",
    "\n",
    "def threadpool_function(country_codes, workers=None):\n",
    "    s_time = time.perf_counter()\n",
    "    #3. create a thread pool to delegate download tasks to      \n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        actual_workers = executor._max_workers\n",
    "        #4. submit task to the thread pool         \n",
    "        to_do = (executor.submit(get_flag, code) for code in country_codes)\n",
    "        #5. return results as soon as the task gets done          \n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "    print(f\"threadpool took: {time.perf_counter() - s_time} seconds\")\n",
    "\n",
    "def processpool_function(country_codes, workers=None):\n",
    "    s_time = time.perf_counter()\n",
    "    #3. create a process pool to delegate download tasks to\n",
    "    with futures.ProcessPoolExecutor(workers) as executor:\n",
    "        actual_workers = executor._max_workers\n",
    "        print(actual_workers) # equal to number of CPU cores\n",
    "        \n",
    "        to_do = (executor.submit(get_flag, code) for code in country_codes)\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "    print(f\"processpool took: {time.perf_counter() - s_time} seconds\")\n",
    "\n",
    "country_codes =\"Yemen Zambia Vietnam Venezuela Ukraine\".lower().split()\n",
    "sequential_io_function(country_codes) # takes around 17.6 seconds\n",
    "# threadpool_function(country_codes) # takes around 4.00 seconds\n",
    "# processpool_function(country_codes) # takes around 4.0 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main thread:139876206409536\n",
      "40\n",
      "inside process: 26510. inside thread:139874753550080\n",
      "inside process: 26510. inside thread:139874233464576\n",
      "inside process: 26510. inside thread:139874216679168\n",
      "inside process: 26510. inside thread:139873696593664\n",
      "inside process: 26510. inside thread:139874267035392\n",
      "inside process: 26510. inside thread:139873730164480\n",
      "inside process: 26510. inside thread:139874778728192\n",
      "inside process: 26510. inside thread:139873679808256inside process: 26510. inside thread:139873704986368\n",
      "\n",
      "inside process: 26510. inside thread:139874225071872inside process: 26510. inside thread:139874770335488\n",
      "\n",
      "inside process: 26510. inside thread:139874250249984\n",
      "inside process: 26510. inside thread:139874241857280\n",
      "inside process: 26510. inside thread:139873721771776\n",
      "inside process: 26510. inside thread:139874787120896\n",
      "inside process: 26510. inside thread:139874761942784\n",
      "inside process: 26510. inside thread:139873713379072\n",
      "inside process: 26510. inside thread:139874258642688\n",
      "inside process: 26510. inside thread:139873688200960\n",
      "inside process: 26510. inside thread:139874795513600\n",
      "40 workers, elapsed time: 15.10s\n"
     ]
    }
   ],
   "source": [
    "# Example of CPU intensive task \n",
    "# Goal of program: generate hash of a very large numbers\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import hashlib\n",
    "from concurrent import futures\n",
    "from random import randrange\n",
    "import threading\n",
    "JOBS = 20\n",
    "SIZE = 2**20\n",
    "STATUS = '{} workers, elapsed time: {:.2f}s'\n",
    "\n",
    "\n",
    "def sha(size):\n",
    "    data = bytearray(randrange(256) for i in range(size))\n",
    "    algo = hashlib.new('sha256')\n",
    "    algo.update(data)\n",
    "    print(f\"inside process: {os.getpid()}. inside thread:{threading.get_ident()}\")\n",
    "    return algo.hexdigest()\n",
    "\n",
    "\n",
    "def sequential_function():\n",
    "    s_time = time.perf_counter() \n",
    "    for i in range(JOBS):\n",
    "        res = sha(SIZE)\n",
    "    print(f\"sequential operation took:{time.perf_counter() - s_time} seconds\")\n",
    "\n",
    "def threadpool_function(workers=None):\n",
    "    t0 = time.time()\n",
    "    print(f\"main thread:{threading.get_ident()}\")\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        actual_workers = executor._max_workers\n",
    "        print(actual_workers)\n",
    "        to_do = (executor.submit(sha, SIZE) for i in range(JOBS))\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "\n",
    "    print(STATUS.format(actual_workers, time.time() - t0))\n",
    "\n",
    "def processpool_function(workers=None):\n",
    "    t0 = time.time()\n",
    "    print(f\"main thread:{threading.get_ident()}\")\n",
    "    with futures.ProcessPoolExecutor(workers) as executor:\n",
    "        actual_workers = executor._max_workers\n",
    "        # print(actual_workers)\n",
    "        to_do = (executor.submit(sha, SIZE) for i in range(JOBS))\n",
    "        for future in futures.as_completed(to_do):\n",
    "            res = future.result()\n",
    "\n",
    "    print(STATUS.format(actual_workers, time.time() - t0))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "#     sequential_function() # takes near 12.95696124099777 seconds\n",
    "#     processpool_function() # takes near 4.21 seconds\n",
    "    threadpool_function() # takes near 12.76 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key findings:\n",
    "\n",
    "\n",
    "### For I/O intensive jobs:\n",
    "Processpool ~ Threadpool > sequential execution\n",
    "\n",
    "### For CPU intensive jobs:\n",
    "1. Processpool > threadpool ~ sequential\n",
    "2. Upper bound on parellel processing via processpool is the number of cores in the machine. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race conditions in Tatkal \n",
    "![title](img/concurrency/race_condition_tatkal_booking.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Interpreter Lock\n",
    "The GIL is a single lock on the interpreter itself which adds a rule that execution of any Python bytecode requires acquiring the interpreter lock. This prevents deadlocks (as there is only one lock) and doesn’t introduce much performance overhead. But it effectively makes any CPU-bound Python program \"single-threaded\".\n",
    "\n",
    "\n",
    "### Note: \n",
    "Every blocking I/O function in the Python standard library releases the GIL, allowing other threads to run. The time.sleep() function also releases the GIL. Therefore, Python threads are perfectly usable in I/O-bound applications, despite the GIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency with asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async behaviour in McDonalds\n",
    "\n",
    "![title](img/concurrency/async_mcdonalds.jpeg)\n",
    "\n",
    "### Blocking and synchronous \n",
    "if you stand in front of the queue while your order is being prepared in kitchen you are blocking next person in line as well as wasting time of the cashier.\n",
    "### Non blocking and asynchronous \n",
    "if you place your order and step aside you allow more people to \"make progress\" and cashier make \"efficient\" use of his time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing comparisons of various operations\n",
    "\n",
    "![title](img/concurrency/io_comparison.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key ingredients\n",
    "## 1. Event Loop\n",
    "You can think of an event loop as something like a while True loop that monitors coroutines, taking feedback on what’s idle, and looking around for things that can be executed in the meantime. It is able to wake up an idle coroutine when whatever that coroutine is waiting on becomes available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions vs Coroutines\n",
    "Functions are entered at one point and exited at another point.\n",
    "\n",
    "Coroutines can be entered, exited, and resumed at many different points. This allows them to give way to other coroutines whike they are waiting on a external dependency.\n",
    "\n",
    "They can be implemented with the\n",
    "1. async def statement.\n",
    "2. asyncio.coroutine decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Task pending coro=<yield_coroutine() running at <ipython-input-18-87acbb59dce3>:23>>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "world\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "# Syntax of a function \n",
    "def simple_function():\n",
    "    print('hello')\n",
    "    #1. blocks the entire thread until the operation is completed.     \n",
    "    time.sleep(1) \n",
    "    print('world')\n",
    "\n",
    "\n",
    "# Syntax of a coroutine\n",
    "\n",
    "# 1. Using async def(more preferable way.)\n",
    "async def async_coroutine():\n",
    "    print('hello')\n",
    "    #2.  Inside a coroutine, when you await on another coroutine,\n",
    "    # you step off the event loop and schedule the awaited coroutine to run *immediately*.\n",
    "    await asyncio.sleep(1) \n",
    "    print('world')\n",
    "\n",
    "# 2. Using asyncio decorator\n",
    "@asyncio.coroutine\n",
    "def yield_coroutine():\n",
    "    print('hello')\n",
    "    #2. yield from statement does two things  \n",
    "    x = yield from asyncio.sleep(1) \n",
    "    print('world')\n",
    "    return\n",
    "    \n",
    "loop = asyncio.get_event_loop()\n",
    "simple_function()    \n",
    "\n",
    "# 3.calling the coroutine directly does not cause it\"s execution but raises warning\n",
    "async_coroutine()\n",
    "\n",
    "#4. By using asyncio.ensure_future you place a task on event loop for execution in future\n",
    "asyncio.ensure_future(async_coroutine(), loop=loop)\n",
    "asyncio.ensure_future(yield_coroutine(), loop=loop)\n",
    "# yield_coroutine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_flag running on thread#139876206409536\n",
      "get_flag running on thread#139876206409536\n",
      "get_flag running on thread#139876206409536\n",
      "get_flag running on thread#139876206409536\n",
      "get_flag running on thread#139876206409536\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "async flag download took 3.295886516571045 seconds\n"
     ]
    }
   ],
   "source": [
    "# I/O intensive job using asyncio\n",
    "# Goal: Download 5 flags\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import asyncio\n",
    "from aiohttp import ClientSession\n",
    "import threading\n",
    "import collections\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "BASE_URL = \"https://cdn.countryflags.com/download\"\n",
    "\n",
    "\n",
    "async def get_flag(cc):\n",
    "    print(f\"get_flag running on thread#{threading.get_ident()}\")\n",
    "    url = f\"{BASE_URL}/{cc}/flag-jpg-small.jpg\"\n",
    "    session = ClientSession()\n",
    "    resp = await session.request(url=url, method='GET',headers={'Content-type': 'image/jpg'})  # <4>\n",
    "    print(resp.status)\n",
    "    image = await resp.read()  # <5>\n",
    "    await session.close()\n",
    "    return image\n",
    "\n",
    "async def download_many(cc_list):\n",
    "    todo = [get_flag(cc) for cc in sorted(cc_list)]  # <9>\n",
    "    await asyncio.gather(*todo)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    country_codes =\"Yemen Zambia Vietnam Venezuela Ukraine\".lower().split()\n",
    "    t0 = time.time()\n",
    "    await download_many(country_codes)\n",
    "    print(f\"async flag download took {time.time() - t0} seconds\")\n",
    "    # asyncio servers and related links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency and parallelism\n",
    "Concurrency is about dealing with lots of things at once.\n",
    "\n",
    "Parallelism is about doing lots of things at once. Not the same, but related.\n",
    "\n",
    "One is about structure, one is about execution.\n",
    "\n",
    "Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.\n",
    "\n",
    "— Rob Pike Co-inventor\n",
    "\n",
    "Co-inventor of the Go language\n",
    "\n",
    "\n",
    "### A simple heuristic:\n",
    "If your solution makes sense in a single core computer it is concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "0. https://stackoverflow.com/questions/868568/what-do-the-terms-cpu-bound-and-i-o-bound-mean\n",
    "1. https://en.wikipedia.org/wiki/Process_(computing)\n",
    "2. https://en.wikipedia.org/wiki/Thread_(computing)\n",
    "3. https://docs.python.org/3.6/library/threading.html\n",
    "4. https://docs.python.org/3/library/concurrent.futures.html\n",
    "5. https://realpython.com/python-gil/\n",
    "6. https://hackernoon.com/a-simple-introduction-to-pythons-asyncio-595d9c9ecf8c\n",
    "7. Fluent Python by Ramalho, Luciano\n",
    "8. https://docs.python.org/3/glossary.html\n",
    "9. https://www.python.org/dev/peps/pep-0492/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
